{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d22839-a72b-4b49-ae0b-96f5abe56964",
   "metadata": {},
   "source": [
    "This notebook implements the algorithm for the estimation of $\\boldsymbol{\\alpha}_{\\text{MAP}}^{j}$ for each $j$:\n",
    "\n",
    "- Inputs:$\\boldsymbol{\\alpha}_0^\\star$, $\\tau$\n",
    "- $\\ell \\gets 0$, $\\nu \\gets +\\infty$\n",
    "- While $ \\nu > \\tau$\n",
    "    - Get $(\\boldsymbol{\\lambda}')_{k=1}^{L}$ i.i.d realizations associated to the density $p_{\\boldsymbol{\\Lambda}}(.\\mid \\boldsymbol{\\alpha}^{\\star}_\\ell)$\n",
    "    - $\\boldsymbol{\\alpha}^{\\star}_{\\ell+1} \\gets \\underset{\\boldsymbol{\\alpha} \\in \\mathcal{A}}{\\text{argmax}}\\:\\hat{p}^{\\boldsymbol{\\alpha}^{\\star}_\\ell}_{L}(\\boldsymbol{y_{1,\\text{obs}}^{-j}}\\mid\\boldsymbol{\\alpha})p_{\\boldsymbol{A}}(\\boldsymbol{\\alpha})$\n",
    "    - $\\nu \\gets \\lVert\\boldsymbol{\\alpha}^{\\star}_{\\ell} - \\boldsymbol{\\alpha}^{\\star}_{\\ell+1}\\lVert$\n",
    "    - $\\ell \\gets \\ell +1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e774a56-fe8b-4cee-950c-0ba727de6357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 10000 #Initial number of i.i.d realizations\n",
    "iter_lim = 100 #Maximum number of iterations\n",
    "\n",
    "alpha_min = -10 #lower bound for alpha\n",
    "alpha_max = 10 #upper bound for alpha\n",
    "delta_alpha = 4 #maximum half width of the interval investigated. The interval will be [max(alpha_min, alpha_star - delta_alpha), min(alpha_max, alpha_star + delta_alpha)] \n",
    "\n",
    "def check_repeat(stored_alpha, new_alpha):\n",
    "    return np.any(np.all(abs(stored_alpha - new_alpha)<10**(-2), axis=1))\n",
    "\n",
    "\n",
    "def investigate_alphamap(index_calib):\n",
    "    alpha_df = np.zeros((len(results_measures), len(index_lambda_q))) #the alpha_map will be stored here\n",
    "    sample_size_df = []\n",
    "    for idx_loo in range(len(results_measures)): #for each observation x_j\n",
    "        print(f\"IDX LOO  {idx_loo}\")\n",
    "\n",
    "        alpha_new = np.array([0.5,0.5]) #initial alpha_star\n",
    "        alpha_star = np.array([10**6]*len(index_lambda_q))\n",
    "\n",
    "        iter=1\n",
    "    \n",
    "        stored_alpha = np.empty((0,len(alpha_star))) #all the alpha_star computed will be stored here\n",
    "        M_used = M #number of i.i.d. realizations\n",
    "\n",
    "        while iter <= iter_lim and np.sqrt(np.sum((alpha_new-alpha_star)**2))> (0.02*len(alpha_star)): #\n",
    "            #print(iter)\n",
    "            #print(np.round(alpha_new,2))\n",
    "            alpha_star = alpha_new.copy()\n",
    "            np.random.seed(123456)\n",
    "            bounds = [(max(alpha_star[ii] - delta_alpha,alpha_min), min(alpha_max, alpha_star[ii]+delta_alpha)) for ii in range(len(alpha_star))] #bounds for the optimization\n",
    "            df_Lambda = sample_Lambda(alpha = alpha_star, M = M_used, index_lambda_p = index_lambda_p, index_lambda_q = index_lambda_q,scale=scale) #sample lambda\n",
    "            Ysimu_list, Ystd_list, stored_likelihoods = get_likelihoods_dflambda(df_Lambda = df_Lambda.values, sigma = sigma, myCODE = myCODE, results_measures = results_measures, index=[index_calib], std_code = True, idx_loo = idx_loo) #compute likelihood\n",
    "            alpha_new = find_map(alpha_star = alpha_star, bounds = bounds, likelihoods_alpha_star = stored_likelihoods, df_Lambda = df_Lambda, index_lambda_p = index_lambda_p, index_lambda_q = index_lambda_q, scale = scale) #optimize a posterior distribution\n",
    "            iter = iter + 1\n",
    "            if check_repeat(stored_alpha, alpha_new): #if this alpha already encountered, increase size of sampling to prevent infinite loop\n",
    "                M_used = M_used + 2000\n",
    "            stored_alpha = np.concatenate([stored_alpha, alpha_new.reshape(1,len(alpha_new))], axis = 0) \n",
    "\n",
    "        alpha_star = alpha_new.copy()\n",
    "\n",
    "        alpha_df[idx_loo] = alpha_star\n",
    "        sample_size_df.append(M_used-2000)\n",
    "        \n",
    "    save_results(pd.DataFrame(alpha_df), \"alpha_df.csv\", pre_path = pre_path, calib = index_calib)\n",
    "    save_results(pd.DataFrame(sample_size_df), \"sample_sizes.csv\", pre_path = pre_path, calib = index_calib)\n",
    "    \n",
    "[investigate_alphamap(index_calib) for index_calib in calib_only]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
