{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287c069c-e86a-4f66-8957-785e18c39439",
   "metadata": {},
   "source": [
    "This notebook provides functions to plot the results\n",
    "\n",
    "The function plot_mean_std plots the mean and standard deviations for each method, and compares it to the true values and the calibration measures. \n",
    "\n",
    "The function dist2 computes the RMSRE between prediction y1 and true values y2.\n",
    "\n",
    "The function compare_errors gathers the RMSRE and levels of prediction intervals of all method, and compute $p^{0.9}_{N,M}$.\n",
    "\n",
    "The function plot_errors plots the RMSRE and $p^{0.9}_{N,M}$ for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0383c20-7d55-4072-be3e-009d3b827587",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = [r\"$\\ell_{F} - \\ell_{0}$\", r\"$r_{F}$\", r\"$\\epsilon_{max}$\"] #names of the three outputs\n",
    "\n",
    "\n",
    "def plot_mean_std(index_calib, pre_path,savefig = False):\n",
    "    \n",
    "    list_values = [true_values, results_measures]\n",
    "    list_sigma = [[0]*3, sigma]\n",
    "    list_labels = [\"True value\", \"Measure\"]\n",
    "\n",
    "    incr = 0.09 #distance between the error bars\n",
    "    plot_hierarchical_plugin = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/plot_alpha_map_lamdba_bayesian.csv\", index_col=0) #get mean and std for hierarchical plugin\n",
    "    plot_full_bayes = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/full_bayes.csv\", index_col=0) # get mean and std for hierarchical full bayes\n",
    "    plot_no_error = pd.read_csv(pre_path + f\"no_error/calib_{index_calib}/plot_alpha_map_lamdba_bayesian.csv\", index_col=0) # get mean and std for no error\n",
    "    plot_unif_error = pd.read_csv(pre_path + f\"uniform_error/calib_{index_calib}/plot_alpha_map_lamdba_bayesian.csv\", index_col=0) #get mean and std for uniform error\n",
    "    elinewidth = 3 #error bar width\n",
    "    markersize = 8 \n",
    "    Ysimu_embed = pd.read_csv(pre_path + f\"embedded_discrepancy/calib_{index_calib}/predictions.csv\", index_col=0) #get mean for embedded discrepancy\n",
    "    Ystd_embed = pd.read_csv(pre_path + f\"embedded_discrepancy/calib_{index_calib}/std_dev.csv\", index_col=0) #get std for embedded discrepancy\n",
    "    \n",
    "    x = np.arange(len(results_measures))\n",
    "    ticks = [f\"$x_{{{k+1}}}$\" for k in x]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(30, 13))  # 3 subplots \n",
    "    \n",
    "    for i, ax in enumerate(axes, start=1):\n",
    "        if index_calib == i: #if the output is the one observed\n",
    "            ax.errorbar(x, (list_values[1][f\"Y{i}\"]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=list_sigma[1][i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='blue', label=list_labels[1],elinewidth=elinewidth, markersize = markersize) #plot measures and variance noise\n",
    "        \n",
    "        ax.scatter(x, list_values[0][f\"Y{i}\"]-list_values[0][f\"Y{i}\"], marker='x', color='blue', label=list_labels[0], s=120,linewidths=4) #plot true values\n",
    "        ax.errorbar(x + incr, (plot_no_error.iloc[:10, i-1]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=plot_no_error.iloc[10:, i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='green', label='No error',elinewidth=elinewidth, markersize = markersize)  #plot no_error\n",
    "        ax.errorbar(x + 2*incr, (plot_unif_error.iloc[:10, i-1]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=plot_unif_error.iloc[10:, i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='red', label='Uniform error',elinewidth=elinewidth,markersize = markersize) #plot uniform error\n",
    "        ax.errorbar(x + 3*incr, (plot_hierarchical_plugin.iloc[:10, i-1]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=plot_hierarchical_plugin.iloc[10:, i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='purple', label=\"Hierarchical \\n     MAP\",elinewidth=elinewidth,markersize = markersize) #plot hierarchical map\n",
    "        ax.errorbar(x + 4*incr, (plot_full_bayes.iloc[:10, i-1]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=plot_full_bayes.iloc[10:, i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='magenta', label=\"Hierarchical \\n full Bayes\",elinewidth=elinewidth,markersize = markersize) #plot full bayes\n",
    "        ax.errorbar(x + 5*incr, (Ysimu_embed.iloc[:, i-1]-list_values[0][f\"Y{i}\"])/list_values[0][f\"Y{i}\"], yerr=Ystd_embed.iloc[:, i-1]/list_values[0][f\"Y{i}\"], fmt='o', color='orange', label=\"Embedded \\ndiscrepancy\",elinewidth=elinewidth,markersize = markersize) #plot embedded discrepancy\n",
    "        ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        ax.set_title(f\"Prediction of {variable_names[i-1]} from measures of {variable_names[index_calib-1]}\", fontsize=42)\n",
    "        \n",
    "        if i == len(axes): #x ticks on the last subplots\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(ticks, fontsize=30)\n",
    "        else:\n",
    "            ax.set_xticks([])  # Remove x-ticks for the first two subplots\n",
    "        \n",
    "        ax.tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    handles, labels = axes[-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='center right', fontsize=30, bbox_to_anchor=(1.15, 0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig: plt.savefig(pre_path + f\"plots/plot_pred_{index_calib}.pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def dist2(y1,y2):\n",
    "    return np.sqrt(np.mean((y1-y2)**2/y2**2))\n",
    "\n",
    "def compare_errors(index_calib, pre_path):\n",
    "    errors_MAP = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/errors_map.csv\", index_col = 0).values.transpose() #get error hierarchical MAP\n",
    "    intervals_MAP = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/intervals_map.csv\", index_col = 0).values #get interval levels hierarchical MAP\n",
    "\n",
    "\n",
    "    errors_bayes = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/errors_bayes.csv\", index_col = 0).values.transpose() #get error full bayes\n",
    "    intervals_bayes = pd.read_csv(pre_path + f\"hierarchical_model/calib_{index_calib}/intervals_bayes.csv\", index_col = 0).values #get interval levels full bayes\n",
    "\n",
    "    errors_allp = pd.read_csv(pre_path + f\"uniform_error/calib_{index_calib}/errors_map.csv\", index_col = 0).values.transpose() #get error uniform error\n",
    "    intervals_allp = pd.read_csv(pre_path + f\"uniform_error/calib_{index_calib}/intervals_map.csv\", index_col = 0).values #get interval levels uniform error\n",
    "\n",
    "    errors_noerror = pd.read_csv(pre_path + f\"no_error/calib_{index_calib}/errors_map.csv\", index_col = 0).values.transpose() #get error no error\n",
    "    intervals_noerror = pd.read_csv(pre_path + f\"no_error/calib_{index_calib}/intervals_map.csv\", index_col = 0).values #get interval levels no error\n",
    "\n",
    "    errors_embed = pd.read_csv(pre_path + f\"embedded_discrepancy/calib_{index_calib}/error_pred.csv\", index_col = 0).values.transpose() #get error embedded discrepancy\n",
    "    intervals_embed = pd.read_csv(pre_path + f\"embedded_discrepancy/calib_{index_calib}/interv_errors.csv\", index_col = 0).values #get error embedded discrepancy\n",
    "\n",
    "    res = pd.DataFrame(np.transpose(np.concatenate([errors_noerror,errors_allp, errors_MAP, errors_bayes, errors_embed]))) #gather prediction errors\n",
    "    columns =[ \"No error\",\"  Uniform \\n errors\",\" Hierarchical \\n MAP\", \"  Hierarchical \\n full Bayes\", \" Embedded \\n discrepancy\"] \n",
    "    nb_compare = 5\n",
    "\n",
    "    res.columns = columns\n",
    "    res.index = np.array(range(3))+1\n",
    "    res_intervals = pd.DataFrame(np.transpose(np.concatenate([[np.apply_along_axis(lambda x: sorted(x)[-2], 0, intervals_noerror)],[np.apply_along_axis(lambda x: sorted(x)[-2], 0, intervals_allp)],[np.apply_along_axis(lambda x: sorted(x)[-2], 0, intervals_MAP)],[np.apply_along_axis(lambda x: sorted(x)[-2], 0, intervals_bayes)], [np.apply_along_axis(lambda x: sorted(x)[-2], 0, intervals_embed)]]))) #gather 90% quantiles of the interval levels\n",
    "    res_intervals.columns = columns\n",
    "\n",
    "    return res, res_intervals\n",
    "\n",
    "\n",
    "def plot_errors(index_calib, pre_path, savefig = False):\n",
    "    errors = compare_errors(index_calib=index_calib, pre_path=pre_path) #Get RMSRE and p^0.9_M,N\n",
    "    errors = errors[0] * 100, errors[1] * 100 #convert to %\n",
    "    names = errors[0].columns\n",
    "    x = np.arange(len(names))\n",
    "    bar_width1 = 23 / 100\n",
    "    bar_width2 = 18 / 100\n",
    "    alph = 0.7\n",
    "    fonttext = 35\n",
    "    loc_bar = [-2 / 3 * bar_width1, 2 / 3 * bar_width2]\n",
    "    loc_bar = loc_bar + [loc_bar[1] + bar_width2, loc_bar[1] + 2 * bar_width2]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(37, 13), sharex=True, sharey=True)  # 3 rows, 1 column\n",
    "\n",
    "    patches = [\n",
    "        mpatches.Patch(color='#1f77b4', label='RMSRE (%)', alpha=alph),\n",
    "        mpatches.Patch(color='green', label=r'$\\hat{p}^{0.9}$ (%)', alpha=alph),\n",
    "    ] # legend\n",
    "\n",
    "    for idx, ax1 in enumerate(axes, start=1):\n",
    "        ax1.bar(x + loc_bar[0], errors[0].iloc[idx-1, :].values, width=bar_width1, alpha=alph) #bars for RMSRE\n",
    "        \n",
    "        ax2 = ax1.twinx() #twin y-axis\n",
    "\n",
    "        ax2.bar(x + loc_bar[1], errors[1].iloc[idx-1, :].values, color=\"green\", width=bar_width1, alpha=alph) #bars for p^0.9\n",
    "\n",
    "        for kk in range(len(x)):\n",
    "            ax1.text(x[kk] + loc_bar[0], errors[0].iloc[idx-1, kk] * 0.95, \"{:.1f}\".format(errors[0].iloc[idx-1, kk]), ha='center', va=\"top\", fontsize=fonttext, fontweight='bold') #text value of rmsre\n",
    "            ax2.text(x[kk] + loc_bar[1], errors[1].iloc[idx-1, kk] * 0.95, str(round(errors[1].iloc[idx-1, kk])), ha='center', va=\"top\", fontsize=fonttext, fontweight='bold') #text value of p^0.9\n",
    "\n",
    "        ax1.tick_params(axis='x', labelsize=30)\n",
    "        ax1.tick_params(axis='y', labelsize=20)\n",
    "        ax2.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "        ax1.locator_params(axis='y', nbins=3)\n",
    "        ax2.locator_params(axis='y', nbins=3)\n",
    "\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(names)\n",
    "\n",
    "        ax1.set_title(f\"Prediction error of {variable_names[idx-1]} from measures of {variable_names[index_calib-1]}\", fontsize=42)\n",
    "\n",
    "    fig.legend(handles=patches, loc='center right', fontsize=40, bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "    fig.text(0.04, 0.5, 'RMSRE (%)', va='center', rotation='vertical', fontsize=38)\n",
    "    fig.text(0.94, 0.5, 'Prediction interval level (%)', va='center', rotation='vertical', fontsize=38)\n",
    "\n",
    "    plt.tight_layout(rect=[0.05, 0, 0.93, 1])  # Adjust layout to make room for y labels\n",
    "\n",
    "    if savefig: plt.savefig(pre_path + f\"plots/plot_err_{index_calib}.pdf\",bbox_inches='tight')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
