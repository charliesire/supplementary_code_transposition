{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d0dfa4-86f9-46b3-99e6-d4863a989047",
   "metadata": {},
   "source": [
    "This notebook focuses on the embedded discrepancy strategy.\n",
    "\n",
    "- The function MCMC_embed generates MCMC_samples for $(\\lambda^1,\\lambda^2)$, from \"index_calib\" the index of the calibration output, \"idx_loo\" the index of the observation $x_j$ that must be removed in the LOO scheme, \"tune_size\" the size of the burnin sample, \"size\" the sample size, and \"rngseed\" the random seed\n",
    "- The function MCMC_multichains generate multichains MCMC samples with the same arguments as MCMC_lambda\n",
    "- The function compute_error_embed takes all the GP means and standard deviations and returns the RMSRE and the levels of the predictions intervals\n",
    "- The function plot_transpo takes the GP means and standard deviations and returns the prediction means and standard deviations\n",
    "- The function MCMC_treat takes the index of the calibration output and the index of the observation $x_j$ that must be removed, and returns all the simulations $f(x_j, \\lambda^1_k + \\lambda^2_k \\xi_r)$ for $1 \\leq k\\leq M$ and $1 \\leq r\\leq R$, more precisely all the GP means and standard deviations\n",
    "- The function results_embed saves for each calibration index the performance metrics, and predictions means and standard deviations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16bcd4-53f9-4ad4-b427-2eba7b268f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCMC_embed(index_calib, idx_loo, tune_size, size, rngseed):\n",
    "    \n",
    "\n",
    "    def priorfun(theta, mu, sigma): #logprior function #theta = (lambda^1, lambda^2)\n",
    "        lambda1 = theta[:len(index_lambda_p)]\n",
    "        lambda2 = theta[len(index_lambda_p):]\n",
    "        if (np.all(lambda2>=0)*int(np.all((lambda1-abs(lambda2))>=0)&np.all((lambda1+abs(lambda2))<=1))) == 0: #On veut s'assurer que lambda^1 + lambda^2 \\xi reste dans les bornes\n",
    "            return 10**10\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def ssfun(theta, data): #loglikelihood \n",
    "        xdata = data.xdata[0]\n",
    "        ydata = data.ydata[0]\n",
    "        lambda1 = theta[:len(index_lambda_p)]\n",
    "        lambda2 = theta[len(index_lambda_p):]\n",
    "        lambda_tot = lambda1+lambda2*u #u est un echantillon de ksi\n",
    "        lambda_tot = lambda_tot*(bMAXlambda-bMINlambda)+bMINlambda \n",
    "        YY, Ystd = myCODE(lambda_tot, index = [index_calib],  std_bool = True, vectorize = True, idx_loo = idx_loo) #compute gp means and std\n",
    "        YY = pd.concat([pd.DataFrame(YY[ii].iloc[:, 0]) for ii in range(len(YY))], axis=1)\n",
    "        Ystd = pd.concat([pd.DataFrame(Ystd[ii].iloc[:, 0]) for ii in range(len(Ystd))], axis=1)\n",
    "        means = np.apply_along_axis(np.mean, 1, YY) #compute the means of the outputs\n",
    "        stds = np.sqrt(np.apply_along_axis(np.var,1,YY) + np.apply_along_axis(np.mean,1, Ystd**2) + sigma[index_calib-1]**2) #compute the stds of the outputs\n",
    "        ss = np.prod(norm.pdf(ydata[:,0], loc = means, scale = stds)) #independent normal approximation\n",
    "        return -2*np.log(ss) \n",
    "\n",
    "    mcstat = MCMC(rngseed=rngseed)\n",
    "    x = np.array(list(set(range(len(results_measures))) - set([idx_loo])))\n",
    "    y = results_measures.loc[list(set(range(len(results_measures))) - set([idx_loo])),f\"Y{index_calib}\"].values\n",
    "    mcstat.data.add_data_set(x, y)\n",
    "    mcstat.simulation_options.define_simulation_options(\n",
    "        nsimu=int(size+tune_size),\n",
    "        updatesigma=False,verbosity = 0, waitbar= False)\n",
    "    mcstat.model_settings.define_model_settings(sos_function=ssfun, prior_function = priorfun)\n",
    "\n",
    "    for ii in range(len(index_lambda_p)):\n",
    "        mcstat.parameters.add_model_parameter(\n",
    "            name=str('$lambda1_{}$'.format(ii + 1)),\n",
    "            theta0=0.5\n",
    "            )\n",
    "    for ii in range(len(index_lambda_p)):\n",
    "        mcstat.parameters.add_model_parameter(\n",
    "            name=str('$lambda2_{}$'.format(ii + 1)),\n",
    "            theta0=0.2\n",
    "            )\n",
    "\n",
    "    mcstat.run_simulation()\n",
    "\n",
    "    return mcstat.simulation_results.results\n",
    "\n",
    "\n",
    "def MCMC_multichains(index_calib, idx_loo,  tune_size, size, rngseed):\n",
    "    np.random.seed(rngseed)\n",
    "    seeds = np.random.randint(1000, size = num_chain) #get seed for each chain\n",
    "    res = [MCMC_embed(index_calib = index_calib, idx_loo = idx_loo, tune_size = tune_size, size = size, rngseed = ss) for ss in seeds] #run every MCMC chain\n",
    "    samples_lambd_post = np.concatenate([res[i][\"chain\"][tune_size:,] for i in range(len(res))]) #concatenate the chains and remove burnin\n",
    "    save_results(data = pd.DataFrame(samples_lambd_post), file = f\"lambd_post_{idx_loo}.csv\", pre_path = pre_path, calib=index_calib)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b3386-022b-49df-acc3-7e0f625e426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_embed(simus, stds):\n",
    "    res = []\n",
    "    res_intervals = []\n",
    "    for idx in [1,2,3]:\n",
    "        pred = np.apply_along_axis(np.mean, 0,simus[idx-1]) #get mean prediction\n",
    "        error = dist2(pred,true_values[f\"Y{idx}\"])\n",
    "        res.append(error)\n",
    "        eta = abs(pred-true_values[f\"Y{idx}\"]).values\n",
    "        intervals = np.apply_along_axis(np.mean, 0, norm.cdf((pred+eta-simus[idx-1])/stds[idx-1]) - norm.cdf((pred-eta-simus[idx-1])/stds[idx-1])) #get levels of interval prediction\n",
    "        res_intervals.append(intervals)\n",
    "    return res, np.transpose(np.array(res_intervals))\n",
    "\n",
    "def plot_transpo(simus, stds):\n",
    "    res_pred = pd.DataFrame()\n",
    "    res_var = pd.DataFrame()\n",
    "    for idx in [1,2,3]: \n",
    "        res_pred = pd.concat([res_pred,pd.DataFrame(np.apply_along_axis(np.mean, 0,simus[idx-1]))], axis=1) #get prediction mean\n",
    "        res_var = pd.concat([res_var,pd.DataFrame(np.apply_along_axis(np.var, 0,simus[idx-1]) + np.apply_along_axis(np.mean, 0,stds[idx-1]**2) )], axis=1) #get prediction variance\n",
    "    return res_pred, np.sqrt(res_var)\n",
    "\n",
    "def MCMC_treat(index_calib, idx_loo):\n",
    "    lambda_post = pd.read_csv(pre_path + f\"/calib_{index_calib}/lambd_post_{idx_loo}.csv\", index_col = 0).values #sample of (lambda^1, lambda^2\n",
    "    Ysimu = pd.DataFrame(np.zeros((0,3)))\n",
    "    Ystd = pd.DataFrame(np.zeros((0,3)))\n",
    "    for i in range(len(lambda_post)):\n",
    "        lambda1 = lambda_post[i,:len(index_lambda_p)]\n",
    "        lambda2 = lambda_post[i,len(index_lambda_p):]\n",
    "        lambda_tot = lambda1 + lambda2*u #u is the sample of ksi\n",
    "        lambda_tot = np.apply_along_axis(lambda x: transform_Lambda(x, index_lambda_p, index_lambda_q), 1, lambda_tot) #compute GP means and stds\n",
    "        res, res_std = myCODE(lambda_tot, index = [1,2,3],  std_bool = True, vectorize = True, idx_loo = idx_loo, new_x = True) #compute GP means and stds\n",
    "        Ysimu = pd.concat([Ysimu, res], axis = 0) \n",
    "        Ystd = pd.concat([Ystd, res_std], axis = 0)\n",
    "    return Ysimu, Ystd #returns all gp means and stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a31b2e-0154-4912-b038-cdd98117c957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def results_embed(index_calib):\n",
    "    print(\"A\")\n",
    "    results = Parallel(n_jobs=-1)(delayed(lambda idx_loo: MCMC_multichains(index_calib = index_calib, idx_loo = idx_loo, tune_size = tune_size, size = size, rngseed = rngseed))(idx_loo) for idx_loo in range(10))\n",
    "    print(\"B\")\n",
    "    results_bis = Parallel(n_jobs=-1)(delayed(lambda idx_loo: MCMC_treat(index_calib = index_calib, idx_loo = idx_loo))(idx_loo) for idx_loo in range(10))\n",
    "    YYtot = [pd.concat([results_bis[jj][0].iloc[:,idx_y] for jj in range(10)], axis=1) for idx_y in range(3)]\n",
    "    YYstdtot = [pd.concat([results_bis[jj][1].iloc[:,idx_y] for jj in range(10)], axis=1) for idx_y in range(3)]\n",
    "\n",
    "    errors = compute_error_embed(YYtot, YYstdtot)\n",
    "    save_results(data = pd.DataFrame(errors[0]), file = \"error_pred.csv\", pre_path = pre_path, calib=index_calib)\n",
    "    save_results(data = pd.DataFrame(errors[1]), file = \"interv_errors.csv\", pre_path = pre_path, calib=index_calib)\n",
    "\n",
    "    to_plot = plot_transpo(YYtot, YYstdtot)\n",
    "    save_results(data = to_plot[0], file = \"predictions.csv\", pre_path = pre_path, calib=index_calib)\n",
    "    save_results(data = to_plot[1], file = \"std_dev.csv\", pre_path = pre_path, calib=index_calib)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff6fee-6e7f-454c-b480-8918ef57b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_lambda_p = [0,1,2,3,4,5]\n",
    "index_lambda_q = []\n",
    "\n",
    "R = 500 #number of samples for ksi\n",
    "\n",
    "np.random.seed(10)\n",
    "lhs = qmc.LatinHypercube(d = len(index_lambda_p), scramble=False, optimization=\"random-cd\", seed = 123) #sample for ksi is obtained with LHS as ksi is uniform\n",
    "u = lhs.random(n=R)*2 - 1\n",
    "\n",
    "tune_size = 3000\n",
    "size = 2000\n",
    "rngseed = 432\n",
    "num_chain = 1\n",
    "\n",
    "[results_embed(index_calib) for index_calib in calib_only]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
